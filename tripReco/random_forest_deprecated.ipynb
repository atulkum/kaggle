{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import time\n",
    "\n",
    "eps = 1e-15\n",
    "\n",
    "%run 'methods.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_finction(y, pred):\n",
    "    total = 0.\n",
    "    for i in range(len(y)):\n",
    "        p = max(min(pred[i][y[i]], (1 - eps)), eps)\n",
    "        total += math.log(p)\n",
    "    return -(total/len(y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare data\n",
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_y = df_train[['VisitNumber', 'TripType']].groupby('VisitNumber').first()\n",
    "\n",
    "le, y = getLabeled(df_y['TripType'])\n",
    "#pickle.dump( y, open( \"y.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#process description \n",
    "df_train['DepartmentDescription'] = df_train['DepartmentDescription'].fillna('')\n",
    "df_words = df_train.groupby('VisitNumber')['DepartmentDescription']\\\n",
    "            .apply(lambda x: '{%s}' % ' '.join(x))\n",
    "  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = None) \n",
    "\n",
    "vectorizer.fit(df_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_features = vectorizer.transform(df_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_words1 = df_words.reset_index()\n",
    "df_words1.set_index('VisitNumber', inplace=True, drop=True)\n",
    "\n",
    "\n",
    "word_count = [len(str(x).strip(\"{}\").split()) for x in df_words1['DepartmentDescription']]\n",
    "word_len = [len(str(x).strip(\"{}\")) for x in df_words1['DepartmentDescription']]\n",
    "\n",
    "df_words1['word_count'] = pd.Series(word_count, index=df_words1.index)\n",
    "df_words1['word_len'] = pd.Series(word_len, index=df_words1.index)\n",
    "df_words1['word_feature'] = pd.Series(train_data_features, index=df_words1.index)\n",
    "\n",
    "df_words1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 37)\t1\n",
      "  (0, 94)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 82)\t1\n",
      "  (1, 97)\t1\n",
      "  (2, 3)\t16\n",
      "  (2, 5)\t18\n",
      "  (2, 21)\t1\n",
      "  (2, 28)\t1\n",
      "  (2, 34)\t1\n",
      "  (2, 41)\t1\n",
      "  (2, 42)\t1\n",
      "  (2, 48)\t1\n",
      "  (2, 55)\t1\n",
      "  (2, 69)\t1\n",
      "  (2, 80)\t16\n",
      "  (2, 83)\t2\n",
      "  (2, 104)\t1\n",
      "  (2, 105)\t2\n",
      "  (3, 57)\t1\n",
      "  (3, 73)\t1\n",
      "  (3, 89)\t2\n",
      "  (4, 18)\t1\n",
      "  (4, 26)\t1\n",
      "  (4, 34)\t2\n",
      "  :\t:\n",
      "  (95671, 48)\t5\n",
      "  (95671, 55)\t3\n",
      "  (95671, 76)\t1\n",
      "  (95671, 81)\t2\n",
      "  (95671, 84)\t1\n",
      "  (95671, 104)\t1\n",
      "  (95672, 21)\t2\n",
      "  (95672, 28)\t1\n",
      "  (95672, 33)\t5\n",
      "  (95672, 34)\t3\n",
      "  (95672, 38)\t1\n",
      "  (95672, 41)\t1\n",
      "  (95672, 42)\t2\n",
      "  (95672, 47)\t5\n",
      "  (95672, 48)\t8\n",
      "  (95672, 55)\t2\n",
      "  (95672, 69)\t1\n",
      "  (95672, 76)\t2\n",
      "  (95672, 84)\t2\n",
      "  (95672, 89)\t2\n",
      "  (95672, 104)\t2\n",
      "  (95673, 28)\t1\n",
      "  (95673, 33)\t1\n",
      "  (95673, 47)\t1\n",
      "  (95673, 48)\t1\n"
     ]
    }
   ],
   "source": [
    "print train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data_features, y, test_size=0.33, random_state=0)\n",
    "forest = RandomForestClassifier(max_depth=2, n_estimators=100, random_state=0)\n",
    "forest = forest.fit(X_train , y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = forest.predict_proba(X_test)\n",
    "loss_finction(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf= KFold(len(y), n_folds=5, shuffle=True, random_state=None)\n",
    "\n",
    "for n_estimator in [50]:#, 300]:#[50, 100, 200]:\n",
    "    for max_depth in [15]:#[13,15]: #[9, 11]:#[2,3,5,7, 9, 11]:\n",
    "        avg = 0\n",
    "        for train_index, test_index in kf:\n",
    "            X_train, X_test = train_data_features[train_index], train_data_features[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            forest = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimator, random_state=0) \n",
    "            forest = forest.fit(X_train , y_train )\n",
    "            y_pred = forest.predict_proba(X_test)\n",
    "            avg += loss_finction(y_test, y_pred)\n",
    "        \n",
    "        print n_estimator, max_depth,\"=>\", avg/len(kf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare submission\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test['DepartmentDescription'] = df_test['DepartmentDescription'].fillna('')\n",
    "df_words_test = df_test.groupby('VisitNumber')['DepartmentDescription']\\\n",
    "            .apply(lambda x: '{%s}' % ', '.join(x))\n",
    "    \n",
    "test_data_features = vectorizer.transform(df_words_test)\n",
    "\n",
    "forest = RandomForestClassifier(max_depth=15, n_estimators=50, random_state=0) \n",
    "forest.fit(train_data_features, y)\n",
    "\n",
    "y_test_pred = forest.predict_proba(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission=pd.read_csv('sample_submission.csv',index_col=0)\n",
    "names = submission.columns.values\n",
    "sub_df = pd.DataFrame(y_test_pred, columns=names)\n",
    "sub_df.set_index(np.unique(df_test['VisitNumber']), inplace=True)\n",
    "sub_df.index.name = 'VisitNumber'\n",
    "#print sub_df.head()\n",
    "\n",
    "millis = int(round(time.time() * 1000))\n",
    "filename = 'rf_desc_sub1%d.csv'%(millis)\n",
    "sub_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dumpPredY(filename, index_col, y_pred):\n",
    "    submission=pd.read_csv('sample_submission.csv',index_col=0)\n",
    "    names = submission.columns.values\n",
    "    sub_df = pd.DataFrame(y_pred, columns=names)\n",
    "    sub_df.set_index(index_col, inplace=True)\n",
    "    sub_df.index.name = 'VisitNumber'\n",
    "    pickle.dump( sub_df, open( filename, \"wb\" ) )\n",
    "    #sub_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred = forest.predict_proba(train_data_features)\n",
    "\n",
    "dumpPredY('test_features.p', np.unique(df_test['VisitNumber']), y_test_pred)\n",
    "dumpPredY('train_features.p', df_words1.index, y_train_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
