{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "eps = 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss function\n",
    "def loss_function(y, pred):\n",
    "    total = 0.\n",
    "    for i in range(len(y)):\n",
    "        p = max(min(pred[i][y[i]], (1 - eps)), eps)\n",
    "        total += math.log(p)\n",
    "    return -(total/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getY(df, le):\n",
    "    df_y = df[['VisitNumber', 'TripType']].groupby('VisitNumber').first()\n",
    "    df_y = df_y.reset_index()\n",
    "    df_y.set_index('VisitNumber', inplace=True, drop=True) \n",
    "    y = le.transform(df_y['TripType']) \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLabeled(col):\n",
    "    col = col.fillna('-1')\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(col)\n",
    "    labeled = le.transform(col) \n",
    "    return le, labeled\n",
    "\n",
    "def getReverseLabled(col, le):\n",
    "    return le.inverse_transform(col)\n",
    "\n",
    "def getTopk(col, k=1000):\n",
    "    col1 = col.dropna()\n",
    "    counts = col1.value_counts()\n",
    "    topk = counts.iloc[0:k].index\n",
    "    top = col.apply(lambda x: x if x in topk else 'other') \n",
    "    return topk, top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTfIDF(col):\n",
    "    count_vect = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 1000)\n",
    "    X_train_counts = count_vect.fit_transform(col)\n",
    "    X_train_counts.shape\n",
    "\n",
    "    tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "    X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "    return X_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submission\n",
    "def generateSubmission(df_features_test, model, classlabel, prefix):\n",
    "    y_test_pred = model.predict_proba(df_features_test)\n",
    "    clumnNames = getReverseLabled(model.classes_, classlabel)\n",
    "    tripClumn = []\n",
    "    for i in clumnNames:\n",
    "        tripClumn.append('TripType_' + str(i))\n",
    "    \n",
    "    sub_df = pd.DataFrame(y_test_pred, columns=tripClumn)\n",
    "    sub_df.set_index(np.unique(df_features_test.index), inplace=True)\n",
    "    sub_df.index.name = 'VisitNumber'\n",
    "\n",
    "    millis = int(round(time.time() * 1000))\n",
    "    filename = '%s_%d'%(prefix, millis)\n",
    "    sub_df.to_csv(filename+'.csv')\n",
    "    \n",
    "    modelFile = open(filename+'.model', 'w')\n",
    "    modelFile.write(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get feature\n",
    "def getFeaturesTrain(df):\n",
    "    df_ScanCount = df[['VisitNumber', 'ScanCount']].groupby('VisitNumber').sum()\n",
    "    df_ScanCount = df_ScanCount.reset_index()\n",
    "    df_ScanCount.set_index('VisitNumber', inplace=True, drop=True)\n",
    "    #weekday\n",
    "    df_w = df[['VisitNumber', 'Weekday']].groupby('VisitNumber').first()\n",
    "    df_w = df_w.reset_index()\n",
    "    df_w.set_index('VisitNumber', inplace=True, drop=True)\n",
    "\n",
    "    weekday = pd.get_dummies(df_w['Weekday'], prefix='Weekday')\n",
    "    weekday['is_wknd'] = ((weekday['Weekday_Sunday'] + weekday['Weekday_Saturday']) > 0)\n",
    "    weekday['is_wknd'] = weekday['is_wknd'].astype(int)\n",
    "    del weekday['Weekday_Friday'] \n",
    "    \n",
    "    #item count per visit\n",
    "    df_count = df.groupby('VisitNumber').apply(lambda x: len(x))\n",
    "    df_count.name = 'itemCount'\n",
    "    \n",
    "    df_features = pd.concat([df_ScanCount, weekday, df_count], axis=1) \n",
    "\n",
    "    return df_features\n",
    "\n",
    "def getFeaturesTest(df):\n",
    "    return getFeaturesTrain(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processDescTrain(df, isUnique):\n",
    "    df.DepartmentDescription = df.DepartmentDescription.fillna('')\n",
    "\n",
    "    df_group = df[['VisitNumber', 'DepartmentDescription']].groupby('VisitNumber')\n",
    "    df_list = None\n",
    "    if isUnique:\n",
    "        df_list = df_group.apply(lambda x: np.unique(list(x.DepartmentDescription)))\n",
    "    else:\n",
    "        df_list = df_group.apply(lambda x: list(x.DepartmentDescription))\n",
    "        \n",
    "    words = df_list.str.join(' ')\n",
    "\n",
    "    vec = CountVectorizer() \n",
    "    vec.fit(words)    \n",
    "    wc = vec.transform(words)\n",
    "    word_count_vector = pd.DataFrame(wc.toarray(), index=df_list.index, columns = vec.get_feature_names())\n",
    "    \n",
    "    word_count_vector['words_count'] = words.apply(lambda x : len(x.split(' ')))\n",
    "    word_count_vector['words_len'] = words.apply(lambda x : len(x))\n",
    "    \n",
    "    return vec, word_count_vector\n",
    "\n",
    "def processDescTest(df, isUnique, vec):\n",
    "    df.DepartmentDescription = df.DepartmentDescription.fillna('')\n",
    "\n",
    "    df_group = df[['VisitNumber', 'DepartmentDescription']].groupby('VisitNumber')\n",
    "    df_list = None\n",
    "    if isUnique:\n",
    "        df_list = df_group.apply(lambda x: np.unique(list(x.DepartmentDescription)))\n",
    "    else:\n",
    "        df_list = df_group.apply(lambda x: list(x.DepartmentDescription))\n",
    "        \n",
    "    words = df_list.str.join(' ')   \n",
    "    wc = vec.transform(words)\n",
    "    word_count_vector = pd.DataFrame(wc.toarray(), index=df_list.index, columns = vec.get_feature_names())\n",
    "    \n",
    "    word_count_vector['words_count'] = words.apply(lambda x : len(x.split(' ')))\n",
    "    word_count_vector['words_len'] = words.apply(lambda x : len(x))\n",
    "    \n",
    "    return word_count_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def getCountVectorTrain(df_train,df_test, columnName, dictCount=1000):\n",
    "    col1_train = df_train[columnName].dropna()\n",
    "    counts_train = col1_train.value_counts()\n",
    "    topk_dict_train = counts_train.index #counts_train.iloc[0:2000].index\n",
    "    \n",
    "    col1_test = df_test[columnName].dropna()\n",
    "    counts_test = col1_test.value_counts()\n",
    "    topk_dict_test = counts_test.iloc[0:min(2000, len(col1_test))].index\n",
    "    \n",
    "    topk_dict = set(topk_dict_train).union(set(topk_dict_test))\n",
    "    \n",
    "    topk_train = df_train[columnName].apply(lambda x: '%s%d'%(columnName, x) if x in topk_dict else '%sother'%(columnName))\n",
    "    \n",
    "    topk_se = pd.Series(topk_train, name=columnName)\n",
    "    df_topk = pd.concat([topk_se, df_train['VisitNumber']], axis=1)\n",
    "    df_topk_gpy = df_topk.groupby('VisitNumber')\n",
    "    df_topk_list = df_topk_gpy.apply(lambda x: list(x[columnName]))\n",
    "    \n",
    "    topk_flat = df_topk_list.str.join(' ')\n",
    "    vec = CountVectorizer() \n",
    "    vec.fit(topk_flat)    \n",
    "    wc = vec.transform(topk_flat)\n",
    "    topk_vector = pd.DataFrame(wc.toarray(), index=df_topk_list.index, columns = vec.get_feature_names())\n",
    "\n",
    "    return topk_dict, vec, topk_vector\n",
    "\n",
    "def getCountVectorTest(df, columnName,topk_dict, vec):\n",
    "    topk = df[columnName].apply(lambda x: '%s%d'%(columnName, x) if x in topk_dict else '%sother'%(columnName)) \n",
    "    \n",
    "    topk_se = pd.Series(topk, name=columnName)\n",
    "    df_topk = pd.concat([topk_se, df['VisitNumber']], axis=1)\n",
    "    df_topk_gpy = df_topk.groupby('VisitNumber')\n",
    "    df_topk_list = df_topk_gpy.apply(lambda x: list(x[columnName]))\n",
    "    \n",
    "    topk_flat = df_topk_list.str.join(' ') \n",
    "    wc = vec.transform(topk_flat)\n",
    "    topk_vector = pd.DataFrame(wc.toarray(), index=df_topk_list.index, columns = vec.get_feature_names())\n",
    "    return topk_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateTestTrainFeature(df_train, df_test):\n",
    "    #generate train feature\n",
    "    other_feature = getFeaturesTrain(df_train)\n",
    "    vec_desc, desc_feature = processDescTrain(df_train, True)\n",
    "    upc_dict, upc_vec, upc_feature = getCountVectorTrain(df_train,df_test, 'Upc')\n",
    "    fileno_dict, fileno_vec, fileno_feature = getCountVectorTrain(df_train, df_test, 'FinelineNumber')\n",
    "    df_features_train = pd.concat([other_feature, desc_feature, upc_feature, fileno_feature], axis=1) \n",
    "    \n",
    "    #generate test feature\n",
    "    other_feature_test = getFeaturesTest(df_test)\n",
    "    desc_feature_test = processDescTest(df_test, True, vec_desc)\n",
    "    upc_feature_test = getCountVectorTest(df_test, 'Upc', upc_dict, upc_vec)\n",
    "    fileno_feature_test = getCountVectorTest(df_test, 'FinelineNumber', fileno_dict, fileno_vec)\n",
    "    df_features_test = pd.concat([other_feature_test, desc_feature_test, upc_feature_test, fileno_feature_test], axis=1) \n",
    "\n",
    "    return df_features_train, df_features_test "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
