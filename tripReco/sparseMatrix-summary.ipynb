{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics, cross_validation, linear_model\n",
    "from scipy import sparse\n",
    "from itertools import combinations\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "%run 'XGBoost_class.ipynb'\n",
    "\n",
    "eps = 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def OneHotEncoder(col):\n",
    "    #(values,counts) = np.unique(col,return_counts=True)\n",
    "    #values[np.argsort(counts)[-2000:]]\n",
    "    col = np.nan_to_num(col)\n",
    "    uniques = np.unique(col)\n",
    "    keymap = dict((key, i) for i, key in enumerate(uniques))\n",
    "    \n",
    "    total_pts = len(col)\n",
    "    num_labels = len(uniques)\n",
    "    \n",
    "    spmat = sparse.lil_matrix((total_pts, num_labels))\n",
    "    for j, val in enumerate(col):\n",
    "        if val[0] in keymap:\n",
    "            spmat[j, keymap[val[0]]] = 1\n",
    "    return keymap, spmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss function\n",
    "def loss_function(y, pred):\n",
    "    eps = 1e-15\n",
    "    total = 0.\n",
    "    for i in range(len(y)):\n",
    "        p = max(min(pred[i][y[i]], (1 - eps)), eps)\n",
    "        total += math.log(p)\n",
    "    return -(total/len(y))\n",
    "def cv_loop(X, y, model, N=10):\n",
    "    #k fold validation\n",
    "    kf= KFold(len(y), n_folds=N, shuffle=True, random_state=None)\n",
    "\n",
    "    mean_score = 0.\n",
    "    i = 0\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_cv, y_train, y_cv = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict_proba(X_cv)\n",
    "        score = loss_function(y_cv, preds)\n",
    "        i += 1\n",
    "        print \"Score (fold %d/%d): %f\" % (i, N, score)\n",
    "        mean_score += score\n",
    "    \n",
    "    print model.get_params()\n",
    "    print \"Score: %f\" % (mean_score/len(kf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareForCountVector(df, columnName, dictCount=2000):\n",
    "    col = df[columnName].dropna()\n",
    "    col = col.fillna('')\n",
    "\n",
    "    counts = col.value_counts()\n",
    "    topk_dict = counts.iloc[0:min(dictCount, len(col))].index\n",
    "    \n",
    "    topk_dict = set(topk_dict).union(set(topk_dict))\n",
    "    topk = df[columnName].apply(lambda x: '%s%d'%(columnName, x) if x in topk_dict else '%sother'%(columnName))\n",
    " \n",
    "    topk_se = pd.Series(topk, name=columnName)\n",
    "    df_topk = pd.concat([topk_se, df['VisitNumber']], axis=1)\n",
    "    return topk_dict, df_topk\n",
    "\n",
    "def getCountVector(df, columnName, isWords, vec=None):\n",
    "    if isWords:\n",
    "        df[columnName] = df[columnName].fillna('')\n",
    "    df_topk_gpy = df.groupby('VisitNumber')\n",
    "    df_topk_list = df_topk_gpy.apply(lambda x: list(x[columnName]))\n",
    "    topk_flat = df_topk_list.str.join(' ')\n",
    "    \n",
    "    if not vec: \n",
    "        vec = CountVectorizer() \n",
    "        vec.fit(topk_flat)    \n",
    "    \n",
    "    wc = vec.transform(topk_flat)\n",
    "    wcar = wc.toarray()\n",
    "    \n",
    "    words_count = topk_flat.apply(lambda x : len(x.split(' '))).reshape(-1,1)\n",
    "    ret = None\n",
    "    if isWords:\n",
    "        words_len = topk_flat.apply(lambda x : len(x)).reshape(-1,1)\n",
    "        ret = np.column_stack([wcar, words_count, words_len])\n",
    "    else:\n",
    "        ret = np.column_stack([wcar, words_count])\n",
    "    \n",
    "    return vec, ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#TripType\tVisitNumber\tWeekday\tUpc\tScanCount\tDepartmentDescription\tFinelineNumber\n",
    "train_df = pd.read_csv('train.csv')\n",
    "num_train = np.shape(train_df)[0]\n",
    "\n",
    "df_y = train_df[['VisitNumber', 'TripType']].groupby('VisitNumber').first()\n",
    "df_y = df_y.reset_index()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df_y.TripType).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_w = train_df[['VisitNumber', 'Weekday']].groupby('VisitNumber').first()\n",
    "df_w = df_w.reset_index()\n",
    "week = OneHotEncoder(df_w.Weekday)\n",
    "\n",
    "is_wknd = np.array(df_w['Weekday']=='Sunday')\n",
    "is_wknd = is_wknd.reshape(-1,1)\n",
    "\n",
    "df_upc = prepareForCountVector(train_df, 'Upc')\n",
    "upc = getCountVector(df_upc[1], 'Upc', False)\n",
    "\n",
    "df_fln = prepareForCountVector(train_df, 'FinelineNumber')\n",
    "fln = getCountVector(df_fln[1], 'FinelineNumber', False)\n",
    "\n",
    "words = getCountVector(train_df, 'DepartmentDescription', True)\n",
    "\n",
    "df_ScanCount = train_df[['VisitNumber', 'ScanCount']].groupby('VisitNumber').sum()\n",
    "df_ScanCount = df_ScanCount.reset_index()\n",
    "scancount = np.array(df_ScanCount.ScanCount)\n",
    "scancount = scancount.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95674, 4127)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = []\n",
    "feature_matrix.append(week[1])\n",
    "feature_matrix.append(is_wknd)\n",
    "feature_matrix.append(upc[1])\n",
    "feature_matrix.append(fln[1])\n",
    "feature_matrix.append(words[1])\n",
    "feature_matrix.append(scancount)\n",
    "\n",
    "feature_matrix = sparse.hstack(feature_matrix).tocsr()\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runXgBoost(feature_matrix, y):\n",
    "    num_classes = len(np.unique(y))\n",
    "\n",
    "    params = {   \n",
    "              'objective': 'multi:softprob',\n",
    "              'eval_metric': 'mlogloss',\n",
    "              'num_class': num_classes,\n",
    "              'eta': 0.3,\n",
    "              'max_depth': 5,\n",
    "              'num_round': 512,\n",
    "              'silent':1\n",
    "    }\n",
    "    for eta in [.05, .08, .1]:\n",
    "        for max_depth in [4,6,8]:\n",
    "            params['eta'] = eta\n",
    "            params['max_depth'] = max_depth\n",
    "                \n",
    "            clfxgb = XGBoostClassifier(**params)\n",
    "            cv_loop(feature_matrix, y, clfxgb)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runRandomForest(feature_matrix, y):\n",
    "    for max_depth in [4, 8, 12, 17, 25, 30, 40, 50]: \n",
    "        clf = RandomForestClassifier(max_depth=max_depth, \\\n",
    "                                        n_estimators=1000, \\\n",
    "                                        min_samples_split=2) \n",
    "        cv_loop(feature_matrix, y, clf)\n",
    "        \n",
    "      \n",
    "def runExRandom(feature_matrix, y):\n",
    "    for max_depth in [4, 8, 12, 17, 25, 30, 40, 50]: \n",
    "        clf = ExtraTreesClassifier(max_depth=max_depth, \\\n",
    "                             n_estimators=1000, \\\n",
    "                             min_samples_split=2) \n",
    "        cv_loop(feature_matrix, y, clf)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (fold 1/10): 2.524722\n",
      "Score (fold 2/10): 2.517027\n",
      "Score (fold 3/10): 2.519336\n",
      "Score (fold 4/10): 2.529887\n",
      "Score (fold 5/10): 2.511664\n",
      "Score (fold 6/10): 2.537348\n",
      "Score (fold 7/10): 2.520378\n",
      "Score (fold 8/10): 2.522375\n",
      "Score (fold 9/10): 2.515665\n",
      "Score (fold 10/10): 2.507850\n",
      "{'warm_start': False, 'oob_score': False, 'n_jobs': 1, 'verbose': 0, 'max_leaf_nodes': None, 'bootstrap': True, 'min_samples_leaf': 1, 'n_estimators': 1000, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'criterion': 'gini', 'random_state': None, 'max_features': 'auto', 'max_depth': 4, 'class_weight': None}\n",
      "Score: 2.520625\n",
      "Score (fold 1/10): 2.179830\n",
      "Score (fold 2/10): 2.178269\n",
      "Score (fold 3/10): 2.186922\n",
      "Score (fold 4/10): 2.181367\n",
      "Score (fold 5/10): 2.177397\n",
      "Score (fold 6/10): 2.182475\n",
      "Score (fold 7/10): 2.190321\n",
      "Score (fold 8/10): 2.185065\n",
      "Score (fold 9/10): 2.178438\n",
      "Score (fold 10/10): 2.180353\n",
      "{'warm_start': False, 'oob_score': False, 'n_jobs': 1, 'verbose': 0, 'max_leaf_nodes': None, 'bootstrap': True, 'min_samples_leaf': 1, 'n_estimators': 1000, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'criterion': 'gini', 'random_state': None, 'max_features': 'auto', 'max_depth': 8, 'class_weight': None}\n",
      "Score: 2.182044\n",
      "Score (fold 1/10): 1.937524\n",
      "Score (fold 2/10): 1.949908\n",
      "Score (fold 3/10): 1.930285\n",
      "Score (fold 4/10): 1.932711\n",
      "Score (fold 5/10): 1.942366\n",
      "Score (fold 6/10): 1.931741\n",
      "Score (fold 7/10): 1.946587\n",
      "Score (fold 8/10): 1.944790\n",
      "Score (fold 9/10): 1.924157\n",
      "Score (fold 10/10): 1.932116\n",
      "{'warm_start': False, 'oob_score': False, 'n_jobs': 1, 'verbose': 0, 'max_leaf_nodes': None, 'bootstrap': True, 'min_samples_leaf': 1, 'n_estimators': 1000, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'criterion': 'gini', 'random_state': None, 'max_features': 'auto', 'max_depth': 12, 'class_weight': None}\n",
      "Score: 1.937219\n",
      "Score (fold 1/10): 1.720623\n",
      "Score (fold 2/10): 1.705542\n",
      "Score (fold 3/10): 1.697102\n",
      "Score (fold 4/10): 1.705407\n",
      "Score (fold 5/10): 1.733436\n",
      "Score (fold 6/10): 1.708012\n",
      "Score (fold 7/10): 1.735466\n",
      "Score (fold 8/10): 1.692832\n",
      "Score (fold 9/10): 1.715147\n",
      "Score (fold 10/10): 1.699304\n",
      "{'warm_start': False, 'oob_score': False, 'n_jobs': 1, 'verbose': 0, 'max_leaf_nodes': None, 'bootstrap': True, 'min_samples_leaf': 1, 'n_estimators': 1000, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'criterion': 'gini', 'random_state': None, 'max_features': 'auto', 'max_depth': 17, 'class_weight': None}\n",
      "Score: 1.711287\n",
      "Score (fold 1/10): 1.464664\n",
      "Score (fold 2/10): 1.461181\n",
      "Score (fold 3/10): 1.461436\n",
      "Score (fold 4/10): 1.470229\n",
      "Score (fold 5/10): 1.446375\n",
      "Score (fold 6/10): 1.473085\n",
      "Score (fold 7/10): 1.453509\n",
      "Score (fold 8/10): 1.474591\n",
      "Score (fold 9/10): 1.451025\n",
      "Score (fold 10/10): 1.458275\n",
      "{'warm_start': False, 'oob_score': False, 'n_jobs': 1, 'verbose': 0, 'max_leaf_nodes': None, 'bootstrap': True, 'min_samples_leaf': 1, 'n_estimators': 1000, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'criterion': 'gini', 'random_state': None, 'max_features': 'auto', 'max_depth': 25, 'class_weight': None}\n",
      "Score: 1.461437\n",
      "Score (fold 1/10): 1.336446\n",
      "Score (fold 2/10): 1.339879\n",
      "Score (fold 3/10): 1.352566\n",
      "Score (fold 4/10): 1.360512\n",
      "Score (fold 5/10): 1.341015\n",
      "Score (fold 6/10): 1.345967\n",
      "Score (fold 7/10): 1.352707\n",
      "Score (fold 8/10): 1.348186\n",
      "Score (fold 9/10): 1.354291\n",
      "Score (fold 10/10): 1.355891\n",
      "{'warm_start': False, 'oob_score': False, 'n_jobs': 1, 'verbose': 0, 'max_leaf_nodes': None, 'bootstrap': True, 'min_samples_leaf': 1, 'n_estimators': 1000, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'criterion': 'gini', 'random_state': None, 'max_features': 'auto', 'max_depth': 30, 'class_weight': None}\n",
      "Score: 1.348746\n",
      "Score (fold 1/10): 1.187525\n",
      "Score (fold 2/10): 1.177522"
     ]
    }
   ],
   "source": [
    "#runXgBoost(feature_matrix, y)\n",
    "runRandomForest(feature_matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runExRandom(feature_matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (fold 2/10): 2.161242\n",
      "Score (fold 3/10): 2.163775\n",
      "Score (fold 4/10): 2.143860\n",
      "Score (fold 5/10): 2.153776\n",
      "Score (fold 6/10): 2.146942\n",
      "Score (fold 7/10): 2.152576\n",
      "Score (fold 8/10): 2.156201\n",
      "Score (fold 9/10): 2.149507\n",
      "Score (fold 10/10): 2.148776\n",
      "Score (fold 11/10): 2.144151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/atulkumar/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/atulkumar/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-94-9fe93fea214d>\", line 18, in runXgBoost\n",
      "    cv_loop(feature_matrix, y, clfxgb)\n",
      "  File \"<ipython-input-89-1db95ae92445>\", line 23, in cv_loop\n",
      "    print forest.get_params()\n",
      "NameError: global name 'forest' is not defined\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/atulkumar/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/atulkumar/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-95-ff83169f6d92>\", line 3, in runRandomForest\n",
      "    forest = RandomForestClassifier(max_depth=max_depth, n_estimators=1000, random_state=0)\n",
      "NameError: global name 'RandomForestClassifier' is not defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pxgb = Process(target=runXgBoost, args=(feature_matrix, y,))\n",
    "pxgb.start()\n",
    "pxgb.join()\n",
    "\n",
    "prf = Process(target=runRandomForest, args=(feature_matrix, y,))\n",
    "prf.start()\n",
    "prf.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Score (fold 2/10): 2.160128\n",
    "Score (fold 3/10): 2.154966\n",
    "Score (fold 4/10): 2.159780\n",
    "Score (fold 5/10): 2.145777\n",
    "Score (fold 6/10): 2.157452\n",
    "Score (fold 7/10): 2.142206\n",
    "Score (fold 8/10): 2.150331\n",
    "Score (fold 9/10): 2.151317\n",
    "Score (fold 10/10): 2.154482\n",
    "Score (fold 11/10): 2.146740\n",
    "{'num_class': 38, 'silent': 1, 'eval_metric': 'mlogloss', 'objective': 'multi:softprob', 'eta': 0.05, 'num_round': 512, 'max_depth': 4}\n",
    "Score: 2.152318\n",
    "Score (fold 2/10): 2.052925\n",
    "Score (fold 3/10): 2.067954\n",
    "Score (fold 4/10): 2.062446\n",
    "Score (fold 5/10): 2.064072\n",
    "Score (fold 6/10): 2.056952\n",
    "Score (fold 7/10): 2.067447\n",
    "Score (fold 8/10): 2.060989\n",
    "Score (fold 9/10): 2.046080\n",
    "Score (fold 10/10): 2.060704\n",
    "Score (fold 11/10): 2.053441\n",
    "{'num_class': 38, 'silent': 1, 'eval_metric': 'mlogloss', 'objective': 'multi:softprob', 'eta': 0.05, 'num_round': 512, 'max_depth': 6}\n",
    "Score: 2.059301\n",
    "Score (fold 2/10): 2.011427\n",
    "Score (fold 3/10): 1.995652\n",
    "Score (fold 4/10): 2.006907\n",
    "Score (fold 5/10): 2.010782\n",
    "Score (fold 6/10): 2.009524\n",
    "Score (fold 7/10): 2.013509\n",
    "Score (fold 8/10): 2.025687\n",
    "Score (fold 9/10): 2.016535\n",
    "Score (fold 10/10): 2.010544\n",
    "Score (fold 11/10): 2.007745\n",
    "{'num_class': 38, 'silent': 1, 'eval_metric': 'mlogloss', 'objective': 'multi:softprob', 'eta': 0.05, 'num_round': 512, 'max_depth': 8}\n",
    "Score: 2.010831\n",
    "Score (fold 2/10): 1.817894\n",
    "Score (fold 3/10): 1.822976\n",
    "Score (fold 4/10): 1.807480\n",
    "Score (fold 5/10): 1.820414\n",
    "Score (fold 6/10): 1.827904\n",
    "Score (fold 7/10): 1.796771\n",
    "Score (fold 8/10): 1.810835\n",
    "Score (fold 9/10): 1.810819\n",
    "Score (fold 10/10): 1.826726\n",
    "Score (fold 11/10): 1.806147\n",
    "{'num_class': 38, 'silent': 1, 'eval_metric': 'mlogloss', 'objective': 'multi:softprob', 'eta': 0.08, 'num_round': 512, 'max_depth': 4}\n",
    "Score: 1.814797\n",
    "Score (fold 2/10): 1.719526\n",
    "Score (fold 3/10): 1.699885\n",
    "Score (fold 4/10): 1.707952\n",
    "Score (fold 5/10): 1.707693\n",
    "Score (fold 6/10): 1.705791\n",
    "Score (fold 7/10): 1.712567\n",
    "Score (fold 8/10): 1.712766\n",
    "Score (fold 9/10): 1.728956\n",
    "Score (fold 10/10): 1.707087\n",
    "Score (fold 11/10): 1.720716\n",
    "{'num_class': 38, 'silent': 1, 'eval_metric': 'mlogloss', 'objective': 'multi:softprob', 'eta': 0.08, 'num_round': 512, 'max_depth': 6}\n",
    "Score: 1.712294\n",
    "Score (fold 2/10): 1.647543\n",
    "Score (fold 3/10): 1.660003\n",
    "Score (fold 4/10): 1.661555\n",
    "Score (fold 5/10): 1.643998\n",
    "Score (fold 6/10): 1.670657\n",
    "Score (fold 7/10): 1.660829\n",
    "Score (fold 8/10): 1.660725\n",
    "Score (fold 9/10): 1.668795\n",
    "Score (fold 10/10): 1.659585\n",
    "Score (fold 11/10): 1.683898\n",
    "{'num_class': 38, 'silent': 1, 'eval_metric': 'mlogloss', 'objective': 'multi:softprob', 'eta': 0.08, 'num_round': 512, 'max_depth': 8}\n",
    "Score: 1.661759\n",
    "Score (fold 2/10): 1.649760\n",
    "Score (fold 3/10): 1.658230\n",
    "Score (fold 4/10): 1.660598\n",
    "Score (fold 5/10): 1.646918\n",
    "Score (fold 6/10): 1.648000\n",
    "Score (fold 7/10): 1.656087\n",
    "Score (fold 8/10): 1.638838\n",
    "Score (fold 9/10): 1.640263\n",
    "Score (fold 10/10): 1.657341\n",
    "Score (fold 11/10): 1.668422\n",
    "{'num_class': 38, 'silent': 1, 'eval_metric': 'mlogloss', 'objective': 'multi:softprob', 'eta': 0.1, 'num_round': 512, 'max_depth': 4}\n",
    "Score: 1.652446\n",
    "Score (fold 2/10): 1.555201\n",
    "Score (fold 3/10): 1.534963\n",
    "Score (fold 4/10): 1.558239\n",
    "Score (fold 5/10): 1.549954\n",
    "Score (fold 6/10): 1.532547\n",
    "Score (fold 7/10): 1.563973\n",
    "Score (fold 8/10): 1.558331\n",
    "Score (fold 9/10): 1.535773\n",
    "Score (fold 10/10): 1.551378\n",
    "Score (fold 11/10): 1.553009\n",
    "{'num_class': 38, 'silent': 1, 'eval_metric': 'mlogloss', 'objective': 'multi:softprob', 'eta': 0.1, 'num_round': 512, 'max_depth': 6}\n",
    "Score: 1.549337\n",
    "Score (fold 2/10): 1.495246\n",
    "Score (fold 3/10): 1.495048\n",
    "Score (fold 4/10): 1.501001\n",
    "Score (fold 5/10): 1.489708\n",
    "Score (fold 6/10): 1.494882\n",
    "Score (fold 7/10): 1.499987\n",
    "Score (fold 8/10): 1.494674\n",
    "Score (fold 9/10): 1.505025\n",
    "Score (fold 10/10): 1.503532\n",
    "Score (fold 11/10): 1.483944\n",
    "{'num_class': 38, 'silent': 1, 'eval_metric': 'mlogloss', 'objective': 'multi:softprob', 'eta': 0.1, 'num_round': 512, 'max_depth': 8}\n",
    "Score: 1.496305\n",
    "Score (fold 2/10): 2.001295\n",
    "Score (fold 3/10): 2.019033\n",
    "Score (fold 4/10): 2.019613\n",
    "Score (fold 5/10): 2.001016\n",
    "Score (fold 6/10): 2.005965\n",
    "Score (fold 7/10): 1.994953\n",
    "Score (fold 8/10): 2.023502\n",
    "Score (fold 9/10): 2.011969\n",
    "Score (fold 10/10): 2.014396\n",
    "Score (fold 11/10): 2.013169\n",
    "{'num_class': 38, 'eval_metric': 'mlogloss', 'objective': 'multi:softprob', 'eta': 0.05, 'num_round': 512, 'max_depth': 8}\n",
    "Score: 2.010491\n",
    "Score (fold 2/10): 2.014759\n",
    "Score (fold 3/10): 2.012488\n",
    "Score (fold 4/10): 2.007637\n",
    "Score (fold 5/10): 2.006032\n",
    "Score (fold 6/10): 2.007296"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
