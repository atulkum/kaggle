{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import TrainSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function(y, pred):\n",
    "    eps = 1e-15\n",
    "    total = 0.\n",
    "    for i in range(len(y)):\n",
    "        p = max(min(pred[i][y[i]], (1 - eps)), eps)\n",
    "        total += math.log(p)\n",
    "    return -(total/len(y))\n",
    "\n",
    "def prepareForCountVector(df, columnName, dictCount=2000, topk_dict=None):\n",
    "    if not topk_dict:\n",
    "        col = df[columnName].dropna()\n",
    "        counts = col.value_counts()\n",
    "        topk_dict = counts.iloc[0:min(dictCount, len(col))].index\n",
    "    \n",
    "        topk_dict = set(topk_dict).union(set(topk_dict))\n",
    "        \n",
    "    col = col.fillna('')\n",
    "    \n",
    "    topk = df[columnName].apply(lambda x: '%s%d'%(columnName, x) if x in topk_dict else '%sother'%(columnName))\n",
    " \n",
    "    topk_se = pd.Series(topk, name=columnName)\n",
    "    df_topk = pd.concat([topk_se, df['VisitNumber']], axis=1)\n",
    "    return topk_dict, df_topk\n",
    "\n",
    "def getCountVector(df, columnName, isWords, vec=None):\n",
    "    if isWords:\n",
    "        df[columnName] = df[columnName].fillna('')\n",
    "    df_topk_gpy = df.groupby('VisitNumber')\n",
    "    df_topk_list = df_topk_gpy.apply(lambda x: list(x[columnName]))\n",
    "    topk_flat = df_topk_list.str.join(' ')\n",
    "    \n",
    "    if not vec: \n",
    "        vec = CountVectorizer() \n",
    "        vec.fit(topk_flat)    \n",
    "    \n",
    "    wc = vec.transform(topk_flat)\n",
    "    wcar = wc.toarray()\n",
    "    \n",
    "    words_count = topk_flat.apply(lambda x : len(x.split(' '))).reshape(-1,1)\n",
    "    ret = None\n",
    "    if isWords:\n",
    "        words_len = topk_flat.apply(lambda x : len(x)).reshape(-1,1)\n",
    "        ret = np.column_stack([wcar, words_count, words_len])\n",
    "    else:\n",
    "        ret = np.column_stack([wcar, words_count])\n",
    "    \n",
    "    return vec, ret\n",
    "\n",
    "def make_submission(clf, X_test, ids, encoder, name='my_neural_net_submission.csv'):\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "    outCols = ['TripType_' + col for col in encoder.classes_]\n",
    "    with open(name, 'w') as f:\n",
    "        f.write('VisitNumber,')\n",
    "        f.write(','.join(outCols))\n",
    "        f.write('\\n')\n",
    "        for id, probs in zip(ids, y_prob):\n",
    "            probas = ','.join([id] + map(str, probs.tolist()))\n",
    "            f.write(probas)\n",
    "            f.write('\\n')\n",
    "    print(\"Wrote submission to file {}.\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def getY(train_df):\n",
    "    df_y = train_df[['VisitNumber', 'TripType']].groupby('VisitNumber').first()\n",
    "    df_y = df_y.reset_index()\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(df_y.TripType).astype(np.int32)\n",
    "    \n",
    "    params = {\n",
    "        'y':y,\n",
    "        'encoder':encoder\n",
    "    }\n",
    "    return params\n",
    "def preprocessData(df, params={}):\n",
    "    df_w = df[['VisitNumber', 'Weekday']].groupby('VisitNumber').first()\n",
    "    df_w = df_w.reset_index()\n",
    "    dict_df_w = df_w[['Weekday']].T.to_dict().values()\n",
    "    dictVec = DictVectorizer()\n",
    "    week = dictVec.fit_transform(dict_df_w)\n",
    "\n",
    "    is_wknd = np.array((df_w['Weekday']=='Sunday') | (df_w['Weekday']=='Saturday'))\n",
    "    is_wknd = is_wknd.reshape(-1,1)\n",
    "\n",
    "    upc_dict, df_upc = prepareForCountVector(df, 'Upc', params.get('upc_dict'))\n",
    "    upc_vec, upc = getCountVector(df_upc, 'Upc', False, params.get('upc_vec'))\n",
    "\n",
    "    fln_dict, df_fln = prepareForCountVector(df, 'FinelineNumber', params.get('fln_dict'))\n",
    "    fln_vec, fln = getCountVector(df_fln, 'FinelineNumber', False, params.get('fln_vec'))\n",
    "\n",
    "    words_vec, words = getCountVector(df, 'DepartmentDescription', True, params.get('words_vec'))\n",
    "\n",
    "    df_ScanCount = df[['VisitNumber', 'ScanCount']].groupby('VisitNumber').sum()\n",
    "    df_ScanCount = df_ScanCount.reset_index()\n",
    "    scancount = np.array(df_ScanCount.ScanCount)\n",
    "    scancount = scancount.reshape(-1,1)\n",
    "    \n",
    "    feature_matrix = []\n",
    "    feature_matrix.append(week)\n",
    "    feature_matrix.append(is_wknd)\n",
    "    feature_matrix.append(upc)\n",
    "    feature_matrix.append(fln)\n",
    "    feature_matrix.append(words)\n",
    "    feature_matrix.append(scancount)\n",
    "\n",
    "    feature_matrix = sparse.hstack(feature_matrix).tocsr()\n",
    "\n",
    "    params = {\n",
    "        'feature_matrix':feature_matrix,\n",
    "        'dictVec': dictVec,\n",
    "        'encoder':encoder,\n",
    "        'upc_vec':upc_vec,\n",
    "        'upc_dict':upc_dict,\n",
    "        'fln_vec':fln_vec,\n",
    "        'fln_dict':fln_dict,\n",
    "        'words':words,\n",
    "        'words_vec':words_vec,\n",
    "        'desc_feature':words\n",
    "    }\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TripType\tVisitNumber\tWeekday\tUpc\tScanCount\tDepartmentDescription\tFinelineNumber\n",
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = preprocessData(train_df)\n",
    "train_y = getY(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "df = train_df\n",
    "df_w = df[['VisitNumber', 'Weekday']].groupby('VisitNumber').first()\n",
    "df_w = df_w.reset_index()\n",
    "dict_df_w = df_w[['Weekday']].T.to_dict().values()\n",
    "dictVec = DictVectorizer()\n",
    "week = dictVec.fit_transform(dict_df_w)\n",
    "\n",
    "is_wknd = np.array((df_w['Weekday']=='Sunday') | (df_w['Weekday']=='Saturday'))\n",
    "is_wknd = is_wknd.reshape(-1,1)\n",
    "\n",
    "upc_dict, df_upc = prepareForCountVector(df, 'Upc', params.get('upc_dict'))\n",
    "upc_vec, upc = getCountVector(df_upc, 'Upc', False, params.get('upc_vec'))\n",
    "\n",
    "fln_dict, df_fln = prepareForCountVector(df, 'FinelineNumber', params.get('fln_dict'))\n",
    "fln_vec, fln = getCountVector(df_fln, 'FinelineNumber', False, params.get('fln_vec'))\n",
    "\n",
    "words_vec, words = getCountVector(df, 'DepartmentDescription', True, params.get('words_vec'))\n",
    "\n",
    "df_ScanCount = df[['VisitNumber', 'ScanCount']].groupby('VisitNumber').sum()\n",
    "df_ScanCount = df_ScanCount.reset_index()\n",
    "scancount = np.array(df_ScanCount.ScanCount)\n",
    "scancount = scancount.reshape(-1,1)\n",
    "    \n",
    "feature_matrix = []\n",
    "feature_matrix.append(week)\n",
    "feature_matrix.append(is_wknd)\n",
    "feature_matrix.append(upc)\n",
    "feature_matrix.append(fln)\n",
    "feature_matrix.append(words)\n",
    "feature_matrix.append(scancount)\n",
    "\n",
    "feature_matrix = sparse.hstack(feature_matrix).tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train, num_features = feature_matrix.shape\n",
    "    \n",
    "num_classes = len(encoder.classes_)\n",
    "print feature_matrix_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#neural network\n",
    "scaler = StandardScaler()\n",
    "feature_matrix_std = scaler.fit_transform(feature_matrix.toarray())\n",
    "sparse_feature_matrix = sparse.csr_matrix(feature_matrix)\n",
    "\n",
    "print feature_matrix_std.shape\n",
    "print sparse_feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "layers0 = [('input', InputLayer),\n",
    "           ('dense0', DenseLayer),\n",
    "           ('dropout', DropoutLayer),\n",
    "           ('dense1', DenseLayer),\n",
    "           ('output', DenseLayer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "net0 = NeuralNet(layers=layers0,\n",
    "                 \n",
    "                 input_shape=(None, num_features),\n",
    "                 dense0_num_units=200,\n",
    "                 dropout_p=0.5,\n",
    "                 dense1_num_units=200,\n",
    "                 output_num_units=num_classes,\n",
    "                 output_nonlinearity=softmax,\n",
    "                 \n",
    "                 update=nesterov_momentum,\n",
    "                 update_learning_rate=0.01,\n",
    "                 update_momentum=0.9,\n",
    "                 \n",
    "                 train_split=TrainSplit(eval_size=0.2),\n",
    "                 verbose=1,\n",
    "                 max_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'more_params': [{'dense0_num_units': 100, 'dense1_num_units': 100}, \\\n",
    "                        {'dense0_num_units': 200, 'dense1_num_units': 200}],\n",
    "        'update_momentum': [0.9, 0.98],\n",
    "        }\n",
    "gs = GridSearchCV(net0, param_grid, cv=2, refit=False, verbose=4)\n",
    "gs.fit(feature_matrix_std, y)\n",
    "\n",
    "print gs.best_score_\n",
    "print gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net0.fit(feature_matrix_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size=0.33, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('train.csv')\n",
    "\n",
    "df_w = test_df[['VisitNumber', 'Weekday']].groupby('VisitNumber').first()\n",
    "df_w = df_w.reset_index()\n",
    "week = enc.transform(df_w.Weekday)\n",
    "\n",
    "is_wknd = np.array(df_w['Weekday']=='Sunday')\n",
    "is_wknd = is_wknd.reshape(-1,1)\n",
    "\n",
    "df_upc = prepareForCountVector(test_df, 'Upc')\n",
    "upc = getCountVector(df_upc[1], 'Upc', False)\n",
    "\n",
    "df_fln = prepareForCountVector(test_df, 'FinelineNumber')\n",
    "fln = getCountVector(df_fln[1], 'FinelineNumber', False)\n",
    "\n",
    "words = getCountVector(train_df, 'DepartmentDescription', True)\n",
    "\n",
    "df_ScanCount = test_df[['VisitNumber', 'ScanCount']].groupby('VisitNumber').sum()\n",
    "df_ScanCount = df_ScanCount.reset_index()\n",
    "scancount = np.array(df_ScanCount.ScanCount)\n",
    "scancount = scancount.reshape(-1,1)\n",
    "\n",
    "feature_matrix = []\n",
    "feature_matrix.append(week[1])\n",
    "feature_matrix.append(is_wknd)\n",
    "feature_matrix.append(upc[1])\n",
    "feature_matrix.append(fln[1])\n",
    "feature_matrix.append(words[1])\n",
    "feature_matrix.append(scancount)\n",
    "\n",
    "feature_matrix = sparse.hstack(feature_matrix).tocsr()\n",
    "num_train, num_features = feature_matrix_std.shape\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
