{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "eps = 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss function\n",
    "def loss_function(y, pred):\n",
    "    total = 0.\n",
    "    for i in range(len(y)):\n",
    "        p = max(min(pred[i][y[i]], (1 - eps)), eps)\n",
    "        total += math.log(p)\n",
    "    return -(total/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getY(df, le):\n",
    "    y = le.transform(df_y['TripType']) \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLabeled(col):\n",
    "    col = col.fillna('-1')\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(col)\n",
    "    labeled = le.transform(col) \n",
    "    return le, labeled\n",
    "\n",
    "def getReverseLabled(col, le):\n",
    "    return le.inverse_transform(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submission\n",
    "def generateSubmission(df_features_test, model, classlabel, prefix):\n",
    "    y_test_pred = model.predict_proba(df_features_test)\n",
    "    clumnNames = getReverseLabled(model.classes_, classlabel)\n",
    "    tripClumn = []\n",
    "    for i in clumnNames:\n",
    "        tripClumn.append('TripType_' + str(i))\n",
    "    \n",
    "    sub_df = pd.DataFrame(y_test_pred, columns=tripClumn)\n",
    "    sub_df.set_index(df_features_test.index, inplace=True)\n",
    "    sub_df.index.name = 'VisitNumber'\n",
    "\n",
    "    df_count = sub_df.groupby('VisitNumber').mean()\n",
    "    df_count = df_count.reset_index()\n",
    "    df_count.set_index('VisitNumber', inplace=True, drop=True)\n",
    "    \n",
    "    millis = int(round(time.time() * 1000))\n",
    "    filename = '%s_%d'%(prefix, millis)\n",
    "    df_count.to_csv(filename+'.csv')\n",
    "    \n",
    "    modelFile = open(filename+'.model', 'w')\n",
    "    modelFile.write(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get feature\n",
    "def getFeaturesTrain(df):\n",
    "    df_ScanCount = df[['VisitNumber', 'ScanCount']]\n",
    "    df_ScanCount.set_index('VisitNumber', inplace=True, drop=True)\n",
    "    #weekday\n",
    "    df_w = df[['VisitNumber', 'Weekday']]\n",
    "    df_w.set_index('VisitNumber', inplace=True, drop=True)\n",
    "\n",
    "    weekday = pd.get_dummies(df_w['Weekday'], prefix='Weekday')\n",
    "    weekday['is_wknd'] = ((weekday['Weekday_Sunday'] + weekday['Weekday_Saturday']) > 0)\n",
    "    weekday['is_wknd'] = weekday['is_wknd'].astype(int)\n",
    "    del weekday['Weekday_Friday'] \n",
    "    \n",
    "    df_features = pd.concat([df_ScanCount, weekday], axis=1) \n",
    "\n",
    "    return df_features\n",
    "\n",
    "def getFeaturesTest(df):\n",
    "    return getFeaturesTrain(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processDescTrain(df, isUnique, vec=None):\n",
    "    df.DepartmentDescription = df.DepartmentDescription.fillna('')\n",
    "\n",
    "    isTrain = False\n",
    "    if not vec:\n",
    "        isTrain = True\n",
    "        vec = CountVectorizer() \n",
    "        vec.fit(df.DepartmentDescription)    \n",
    "    wc = vec.transform(df.DepartmentDescription)\n",
    "    word_count_vector = pd.DataFrame(wc.toarray(), index=df.index, columns = vec.get_feature_names())\n",
    "    \n",
    "    word_count_vector['words_count'] = df.DepartmentDescription.apply(lambda x : len(x.split(' ')))\n",
    "    word_count_vector['words_len'] = df.DepartmentDescription.apply(lambda x : len(x))\n",
    "    if isTrain:\n",
    "        return vec, word_count_vector\n",
    "    else:\n",
    "        return word_count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def getCountVectorTrain(df_train,df_test, columnName, dictCount=1000):\n",
    "    col1_train = df_train[columnName].dropna()\n",
    "    counts_train = col1_train.value_counts()\n",
    "    topk_dict_train = counts_train.iloc[0:min(dictCount, len(col1_train))].index\n",
    "    \n",
    "    col1_test = df_test[columnName].dropna()\n",
    "    counts_test = col1_test.value_counts()\n",
    "    topk_dict_test = counts_test.iloc[0:min(dictCount, len(col1_test))].index\n",
    "    \n",
    "    topk_dict = set(topk_dict_train).union(set(topk_dict_test))\n",
    "    \n",
    "    topk_train = df_train[columnName].apply(lambda x: '%s%d'%(columnName, x) if x in topk_dict else '%sother'%(columnName))\n",
    "    \n",
    "    vec = CountVectorizer() \n",
    "    vec.fit(topk_train)    \n",
    "    wc = vec.transform(topk_train)\n",
    "    topk_vector = pd.DataFrame(wc.toarray(), index=df_train['VisitNumber'], columns = vec.get_feature_names())\n",
    "\n",
    "    return topk_dict, vec, topk_vector\n",
    "\n",
    "def getCountVectorTest(df, columnName,topk_dict, vec):\n",
    "    topk = df[columnName].apply(lambda x: '%s%d'%(columnName, x) if x in topk_dict else '%sother'%(columnName)) \n",
    "    \n",
    "    wc = vec.transform(topk)\n",
    "    topk_vector = pd.DataFrame(wc.toarray(), index=df['VisitNumber'], columns = vec.get_feature_names())\n",
    "    return topk_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateTestTrainFeature(df_train, df_test):\n",
    "    #generate train feature\n",
    "    other_feature = getFeaturesTrain(df_train)\n",
    "    vec_desc, desc_feature = processDescTrain(df_train, True)\n",
    "    upc_dict, upc_vec, upc_feature = getCountVectorTrain(df_train,df_test, 'Upc')\n",
    "    fileno_dict, fileno_vec, fileno_feature = getCountVectorTrain(df_train, df_test, 'FinelineNumber')\n",
    "    df_features_train = pd.concat([other_feature, desc_feature, upc_feature, fileno_feature], axis=1) \n",
    "    \n",
    "    #generate test feature\n",
    "    other_feature_test = getFeaturesTest(df_test)\n",
    "    desc_feature_test = processDescTest(df_test, True, vec_desc)\n",
    "    upc_feature_test = getCountVectorTest(df_test, 'Upc', upc_dict, upc_vec)\n",
    "    fileno_feature_test = getCountVectorTest(df_test, 'FinelineNumber', fileno_dict, fileno_vec)\n",
    "    df_features_test = pd.concat([other_feature_test, desc_feature_test, upc_feature_test, fileno_feature_test], axis=1) \n",
    "\n",
    "    return df_features_train, df_features_test "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
